import r2pipe
import os
import networkx as nx
import time
import pandas as pd
import numpy as np
import pickle
from param_parser import parameter_parser
import concurrent.futures
from timeout_decorator import timeout
from func_timeout import func_set_timeout
import func_timeout
from sentence_transformers import SentenceTransformer


@func_set_timeout(1800)
def extract_fcg_radare2(input: str, filename: str, output: str):
    filenamePrefix = filename[:2]
    outputPath = os.path.join(output, filename) + ".gpickle"
    x_file = os.path.join("./embedding_pickle/", filename + ".pickle")
    # if os.path.isfile(outputPath):
    #     return
    if not os.path.isfile(x_file):
        with open("./errorLog.txt", "a") as f:
            f.write(f"There is no embedding pickle file for this sample: {filename}\n")
            f.close()
        return
    input = input + filenamePrefix
    samplePath = os.path.join(input, filename)
    r2 = r2pipe.open(samplePath, flags=["-2"])
    r2.cmd("aaaa")
    command = "agCd"
    dotString = r2.cmd(command)
    G = nx.DiGraph()
# r2.cmd("agCd > test.dot")
# # netwokx graph from dot string
# G = nx.nx_pydot.read_dot("test.dot")
    label = {}
    if len(dotString.split("\n")) < 9:
        with open("./errorLog.txt", "a") as f:
            f.write(f"No function in this file: {filename}\n")
            f.close()
        return
    for lines in dotString.split("\n"):
        tmp = []
        for words in lines.split():
            if words[0] == '"':
                words = words.replace('"', "")
            tmp.append(words)
        try:
            if tmp[1][1] == "l":
                func = tmp[0]
                label[tmp[0]] = func
        except:
            pass

    for lines in dotString.split("\n"):
        tmp = []
        for words in lines.split():
            if words[0] == '"':
                words = words.replace('"', "")
            tmp.append(words)
        try:
            if tmp[1] == "->":
                G.add_edge(label[tmp[0]], label[tmp[2]])
        except:
            pass
    r2.cmd("quit")

    G = load_x_vector(filename, G)

    with open(outputPath, "wb") as f:
        pickle.dump(G, f)
        f.close()


def load_x_vector(filename, G):
    input_path = os.path.join("./embedding_pickle/", filename + ".pickle")
    with open(input_path, "rb") as f:
        embedding = pickle.load(f)
        f.close()
    for node in G.nodes():
        G.nodes[node]["x"] = embedding[node]
    return G



def process_file(file, total, dataset):
    global count
    label = dataset.loc[dataset["filename"] == file, "label"].iloc[0]
    if label == "malware":
        input = args.input_malware
    else:
        input = args.input_benignware
    print(f"\rProgress: {file}({count}/{total})", end="", flush=True)
    try:
        extract_fcg_radare2(
            input,
            file,
            args.output + "/fcg_gpickle",
        )
        count += 1
    except func_timeout.exceptions.FunctionTimedOut:
        print(f"Time out: {file}")


def main(args):
    print(f"Malware root folder: {args.input_malware}")
    print(f"Benignware root folder: {args.input_benignware}")
    print(f"Dataset path: {args.input_dataset}")
    start_time = time.time()
    dataset = pd.read_csv(args.input_dataset)
    file_list = dataset["filename"]
    concurrency = 20
    global count
    count = 0
    total = len(file_list)
    with concurrent.futures.ThreadPoolExecutor(max_workers=concurrency) as executor:
        futures = [
            executor.submit(process_file, file, total, dataset) for file in file_list
        ]
        for future in concurrent.futures.as_completed(futures):
            try:
                future.result()
            except Exception as e:
                print(f"An error occurred: {e}")

    end_time = time.time()
    execution_time_seconds = end_time - start_time
    print("Execution time: ", execution_time_seconds)


if __name__ == "__main__":
    args = parameter_parser()
    main(args)
