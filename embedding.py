import pandas as pd
import numpy as np
import os
import pickle
import torch
import torch.nn as nn
import gc


def load_opcode_set(opcode_pickle_folder):
    print("Loading opcode set...")
    set_opcode = set()
    count_set_opcode = {}
    count = 0
    for pickle_file in os.listdir(opcode_pickle_folder):
        file_amount = len(os.listdir(opcode_pickle_folder))
        if pickle_file.endswith(".pickle"):
            print(
                f"\rNow processing: {pickle_file} ({count}/{file_amount})",
                end="",
                flush=True,
            )
            pickle_path = os.path.join(opcode_pickle_folder, pickle_file)
            dic = pd.read_pickle(pickle_path)
            for key in dic:
                the_function_set = set(dic[key])
                set_opcode.update(dic[key])
                for opcode in the_function_set:
                    if opcode in count_set_opcode:
                        count_set_opcode[opcode] += 1
                    else:
                        count_set_opcode[opcode] = 1

            count += 1
    print("\nOpcode set size: " + str(len(set_opcode)))
    # sort count_set_opcode by value
    count_set_opcode = sorted(
        count_set_opcode.items(), key=lambda x: x[1], reverse=True
    )
    return count_set_opcode


def MyEmbedding(vocab_size, embedding_dim):
    torch.manual_seed(5)
    embedding = nn.Embedding(vocab_size, embedding_dim)
    return embedding


def instruction_module(opcode_pickle_folder, embedding_output_folder, opcode_set):
    print("Instruction module...")
    vocab_size = len(opcode_set)
    embedding_dim = 100
    embedding_modle = MyEmbedding(vocab_size, embedding_dim)
    count = 0
    file_amount = len(os.listdir(opcode_pickle_folder))
    for pickle_file in os.listdir(opcode_pickle_folder):
        if pickle_file.endswith(".pickle"):
            print(
                f"\rNow processing: {pickle_file} ({count}/{file_amount})",
                end="",
                flush=True,
            )
            embedding = {}
            embedding_mean_x = {}
            embedding_path = os.path.join(embedding_output_folder, pickle_file)
            pickle_path = os.path.join(opcode_pickle_folder, pickle_file)
            with open(pickle_path, "rb") as file:
                dic = pickle.load(file)
                try:
                    for key in dic:
                        function_embedding = []
                        for opcode in dic[key]:
                            if opcode in opcode_set:
                                function_embedding.append(opcode_set.index(opcode))
                        embedding[key] = embedding_modle(
                            torch.LongTensor(function_embedding)
                        )
                        embedding_mean_x[key] = torch.mean(embedding[key], dim=0)
                    with open(embedding_path, "wb") as f:
                        pickle.dump(embedding_mean_x, f)
                        f.close()
                except Exception as e:
                    print(f"Exception: {e}, {pickle_file}")
                    continue
                file.close()
            del dic
        count += 1


def main():
    opcode_pickle_folder = "./graph_data/fcgOpcode_pickle/"
    embedding_output_folder = "./graph_data/embedding_pickle/"
    #embedding_output_folder2 = "./embedding_torch_pickle/"
    if not os.path.exists("opcode_set.pickle"):
        count_set_opcode = load_opcode_set(opcode_pickle_folder)
        new_opcode_set = []
        for i in range(500):
            print(f"{count_set_opcode[i][0]}: {count_set_opcode[i][1]}")
            new_opcode_set.append(count_set_opcode[i][0])
        with open("opcode_set.pickle", "wb") as f:
            pickle.dump(new_opcode_set, f)
            f.close()
    else:
        with open("opcode_set.pickle", "rb") as f:
            new_opcode_set = pickle.load(f)
            f.close()
    instruction_module(opcode_pickle_folder, embedding_output_folder, new_opcode_set)


if __name__ == "__main__":
    main()
