from malwareDetector.detector import detector
from typing import Any
import numpy as np
import os
import r2pipe
import networkx as nx
import pickle
import torch
import torch.nn as nn
from torch_geometric.utils.convert import from_networkx
from trainModel import trainModel
from trainModel import SAGE
import pandas as pd

class subDetector(detector):
    def __init__(self) -> None:
            super().__init__()

    def extractFeature(self, inputSample: str, filename: str, outputFolder: str) -> Any:
        print("Radare2 feature extraction...")
        r2 = r2pipe.open(inputSample)
        r2.cmd("aaaa")
        command = 'agCd'
        dotString = r2.cmd(command)
        G = nx.DiGraph()
# r2.cmd("agCd > test.dot")
# # netwokx graph from dot string
# G = nx.nx_pydot.read_dot("test.dot")
        label = {} # key: node addr, value: function name
        function_opcode_mapping = {} # key: node addr, value: list of opcodes
        if len(dotString.split('\n')) < 9:
            print(f'No function in this file: {filename}\n')
            return
        for lines in dotString.split('\n'):
            tmp = []
            for words in lines.split():
                if words[0] == '"':
                    words = words.replace('"', '')
                tmp.append(words)
            try:
                if tmp[1][1] == 'l': # is a node
                    func = tmp[1][7:]
                    func = func.replace('"', '')
                    label[tmp[0]] = func
                    piCommand = "pif @" + tmp[0] + "~[0]"
                    Instructions = r2.cmd(piCommand)
                    opcode_list = []
                    if Instructions:
                        opcode_list = Instructions.split('\n')
                    function_opcode_mapping[func] = opcode_list
            except:
                pass

        for lines in dotString.split('\n'):
            tmp = []
            for words in lines.split():
                if words[0] == '"':
                    words = words.replace('"', '')
                tmp.append(words)
            try:
                if tmp[1] == '->':
                    G.add_edge(label[tmp[0]], label[tmp[2]])
            except:
                pass

        for node in G.nodes(): # add x attribute to each node
            G.nodes[node]['x'] = function_opcode_mapping[node]
        
        r2.cmd("quit")

        outputPath = os.path.join(outputFolder, filename) + ".gpickle"
        with open(outputPath, "wb") as f:
            pickle.dump(G, f)
            f.close()
        return G

    def generate_opcode_set(opcode_pickle_folder, opcodeSetLength):
        print("Loading opcode set...")
        set_opcode = set()
        count_set_opcode = {}
        count = 0
        for pickle_file in os.listdir(opcode_pickle_folder):
            file_amount = len(os.listdir(opcode_pickle_folder))
            if pickle_file.endswith(".pickle"):
                print(
                    f"\rNow processing: {pickle_file} ({count}/{file_amount})",
                    end="",
                    flush=True,
                )
                pickle_path = os.path.join(opcode_pickle_folder, pickle_file)
                dic = pd.read_pickle(pickle_path)
                for key in dic:
                    the_function_set = set(dic[key])
                    set_opcode.update(dic[key])
                    for opcode in the_function_set:
                        if opcode in count_set_opcode:
                            count_set_opcode[opcode] += 1
                        else:
                            count_set_opcode[opcode] = 1

                count += 1
        print("\nOpcode set size: " + str(len(set_opcode)))
        # sort count_set_opcode by value
        count_set_opcode = sorted(
            count_set_opcode.items(), key=lambda x: x[1], reverse=True
        )
        new_opcode_set = []
        for i in range(opcodeSetLength):
            print(f"{count_set_opcode[i][0]}: {count_set_opcode[i][1]}")
            new_opcode_set.append(count_set_opcode[i][0])
        with open("opcode_set.pickle", "wb") as f:
            pickle.dump(new_opcode_set, f)
            f.close()
        return new_opcode_set

    def MyEmbedding(vocab_size, embedding_dim):
        torch.manual_seed(5)
        embedding = nn.Embedding(vocab_size, embedding_dim)
        return embedding

    def vectorize(self, graph: nx.DiGraph, opcodeSet: list, filename: str, outputFolder: str) -> torch.Tensor:
        print("Vectorization...")
        vocab_size = len(opcodeSet)
        embedding_dim = 100
        embedding_modle = self.MyEmbedding(vocab_size, embedding_dim)
        embedding = {}
        embedding_mean_x = {}
        try:
            for node in graph.nodes():
                function_embedding = []
                for opcode in graph.nodes[node]["x"]:
                    if opcode in opcodeSet:
                        function_embedding.append(opcodeSet.index(opcode))
                embedding[node] = embedding_modle(torch.LongTensor(function_embedding))
                embedding_mean_x[node] = torch.mean(embedding[node], dim=0)
                del graph.nodes[node]["x"]
                graph.nodes[node]["x"] = embedding_mean_x[node]
        except Exception as e:
            print(f"Exception: {e}")
            return
        for node in graph.nodes():
            graph.nodes[node]['x'] = torch.nan_to_num(graph.nodes[node]['x'], nan=0.0)
        torch_data = from_networkx(graph)

        outputPath = os.path.join(outputFolder, filename) + ".pickle"
        with open(outputPath, "wb") as f:
            pickle.dump(torch_data, f)
            f.close()

        return torch_data

    def model(self, training:bool=True) -> Any:
        if training == True:
            print("Training model...")
            trainModel(self.config)
        print("Model...")
        model = torch.load(self.config.folder.model + self.config.modelName, map_location=torch.device('cpu'))
        print(model)        
        return model

        
    def predict(self,data: torch.Tensor, model: Any) -> np.array:
        print("Predict...")
        model.eval()
        batch = torch.zeros(data.x.shape[0], dtype=torch.long)
        predict = model(data.x, data.edge_index, batch)
        predict = torch.softmax(predict, dim=1)

        return predict.numpy()
    
    def write_to_file(inputPath: str, outputPath: str, result: np.array):
        if '.csv' not in outputPath:
            outputPath = outputPath + '.csv'
        
        if not os.path.exists(outputPath):
            with open(outputPath, 'w') as f:
                line = 'Filename,Benign,Malware\n'
                f.write(line)
        
        with open(outputPath, 'a') as f:
            filename = os.path.basename(inputPath)
            line = filename + ',' + str(result[0]) + ',' + str(result[1]) + '\n'
            f.write(line)